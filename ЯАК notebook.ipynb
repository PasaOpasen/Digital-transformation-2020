{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Пакеты"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import math\n\nfrom collections import defaultdict\nfrom functools import lru_cache\nfrom enum import Enum\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom scipy import stats\n\n\nfrom matplotlib import pyplot as plt\nfrom matplotlib.pyplot import imshow\nfrom PIL import Image\n%matplotlib inline\n\n\nfrom pylab import rcParams\n\nrcParams['figure.figsize'] = 18, 8\n\n\n!pip install BeeHiveOptimization\nfrom BeeHiveOptimization import Bees, Hive, BeeHive\n\n!pip install geneticalgorithm\nfrom geneticalgorithm import geneticalgorithm as ga # пакет с простым генетическим алгоритмом","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Идея алгоритма"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"codes = [\n    '00000072_000',\n    '00000150_002',\n    '00000181_061',\n    '00002578_000',\n    '00003400_003',\n    '00001075_024'\n]\n\n\n\nfor ind in codes:\n    \n    origin = Image.open(f'../input/digital-transformation-2020/Dataset/Dataset/Origin/{ind}.png')\n    \n    expert = Image.open(f'../input/digital-transformation-2020/Dataset/Dataset/Expert/{ind}_expert.png')\n\n    model1 = Image.open(f'../input/digital-transformation-2020/Dataset/Dataset/sample_1/{ind}_s1.png')\n\n    model2 = Image.open(f'../input/digital-transformation-2020/Dataset/Dataset/sample_2/{ind}_s2.png')\n    \n    model3 = Image.open(f'../input/digital-transformation-2020/Dataset/Dataset/sample_3/{ind}_s3.png')\n    \n    fig, axes = plt.subplots(1, 5)\n\n    \n    axes[0].imshow(np.asarray(origin))\n    axes[0].set_title(f\"Оригинальный снимок\")\n    \n    axes[1].imshow(np.asarray(expert))\n    axes[1].set_title(f\"Маска эксперта\")\n    \n    axes[2].imshow(np.asarray(model1))\n    axes[2].set_title(f'Маска модели 1')\n\n    axes[3].imshow(np.asarray(model2))\n    axes[3].set_title(f'Маска модели 2')\n    \n    axes[4].imshow(np.asarray(model3))\n    axes[4].set_title(f'Маска модели 3')\n\n    fig.set_figwidth(18)    #  ширина и\n    fig.set_figheight(10)    #  высота \"Figure\"\n\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"В файле *\"../input/digital-transformation-2020/Dataset/Dataset/DX_TEST_RESULT_FULL.csv\"* хранятся данные, которые мы сводим к следующему: **для каждого снимка некоторая модель выдает один набор фигур, а эксперт -- другой, причем этот набор фигур может быть и пустым**. Отличие модельной конфигурации от экспертной эксперт субъективно определяет по шкале от 1 до 5 (чем больше, тем лучше).\n\nАлгоритм заключается в следующем: **сходство двух изображений определяется количеством штрафа, наложенного за разные необходимые трансформации фигур одного изображения в фигуры другого**.\n\nШтрафы назначаются за следующие действия:\n\n* если требуется создать (недостающую) фигуру, которая есть у эксперта и которой нет у модели, налается штраф, пропорциональный площади этой фигуры\n* если требуется удалить (лишнюю) фигуру, которой нет у эксперта, но которая есть у модели, налается штраф, пропорциональный площади этой фигуры\n* если нужно преобразовать эллипс или наоборот (у модели эллипс, а у эксперта там -- прямоугольник), налагается свой штраф, связанный с площадями\n* если требуется переместить фигуру модели на некоторое расстояние, чтобы центры фигур модели и эксперта совпали, налается штраф, пропорциональный расстоянию\n* если требуется увеличить/уменьшить фигуру модели по вертикали/горизонтали (чтоб получить фигуру эксперта), за каждое такое изменение налается свой штраф\n* кроме этого, налагается штраф, пропорциональный числу несоответствующих (непарных) фигур между конфигурациями модели и эксперта (если у эксперта есть только одна фигура, а модель нашла 10, это нехорошо)\n\nКак определятся, что две разные фигуры у модели и эксперта на самом деле идентичны и должны сводиться одна в другую? Для этого есть параметр `tresh`. Если расстояние между центрами фигур меньше этого параметра, они будут идентичны. При этом пара идентичных фигур выбирается как пара фигур с минимальным расстоянием, меньшим `tresh`.\n\nТаким образом, **для каждой пары изображений мы можем вычислить требуемый набор трансформаций, за каждую трансформацию наложить свой штраф, а сумма штрафов будет выражать степень схожести изображений**.\n\nСами штрафы за каждую трансформацию подбираются эволюционным алгоритмом. Цель алгоритма при подборе штрафов -- минимизировать корреляцию Спирмена (устремить к -1) между получаемыми суммами штрафов (в неизвестно каких диапазонах) и целевыми оценками (в диапазоне от 1 до 5). После этого, для преведения наших оценок к целевому диапазону используется простая линейная регрессия с трансформацией данных. "},{"metadata":{},"cell_type":"markdown","source":"# Нужные классы"},{"metadata":{"trusted":true},"cell_type":"code","source":"class Shape(Enum):\n    circle = 0\n    rect = 1\n\n\nclass Point:\n    \"\"\"\n    точка на плоскости\n    \"\"\"\n    def __init__(self, x, y):\n        self.x = x\n        self.y = y\n    \n    @staticmethod    \n    def dist(A, B):\n        return math.hypot(A.x - B.x, A.y - B.y)\n\nclass Figure:\n    \"\"\"\n    фигура (не имеет особого прям значения, эллипс это или прямоугольник)\n    \"\"\"\n    def __init__(self, center, horizontal, vertical, shape):\n        self.center = center\n        self.hor = horizontal\n        self.ver = vertical\n        \n        self.shape = Shape.circle if shape == 'circle' else Shape.rect\n        \n        self.S = 4 * self.hor * self.ver if self.shape == Shape.rect else math.pi * self.hor * self.ver # площадь фигуры\n        \n    def S_diff(self): # разность площади между прямоугольником и эллипсом\n        return self.hor * self.ver * (4 - math.pi)\n    \n    @staticmethod\n    def dist(A, B):\n        \"\"\"\n        расстояние между центрами фигур\n        \"\"\"\n        return Point.dist(A.center, B.center)\n    \n    \n    @staticmethod\n    def transforms(model, expert): # считает наказания за трансформации\n        \"\"\"\n        возвращает массив наказаний за увеличение/уменьшение фигуры model по вертикали/горизонтали так, чтобы сводить ее в фигуру expert\n        \n        формула наказания -- это большее/меньшее * на размер у expert\n        \n        таким образом, если нужно уменьшить вертикаль в два раза с 10 до 5, это не так страшно, как уменьшать вертикаль в 2 раза с 100 до 50\n        \n        больше-меньше/вертикаль-горизонталь выводятся отдельно, чтобы за них была отдельная ошибка\n        \"\"\"\n                \n        if model.ver > expert.ver: # если надо уменьшать вертикаль\n            ver_up, ver_down = 0, model.ver #/expert.ver \n        elif model.ver < expert.ver and model.ver > 0: # если надо увеличивать вертикаль\n            ver_up, ver_down = expert.ver**2 / model.ver, 0\n        else:\n            ver_up, ver_down = 0, 0\n        \n        \n        if model.hor > expert.hor: # если надо уменьшать горизонталь\n            hor_up, hor_down = 0, model.hor #/expert.hor \n        elif model.hor < expert.hor and model.hor > 0:\n            hor_up, hor_down = expert.hor**2 / model.hor, 0\n        else:\n            hor_up, hor_down = 0, 0\n        \n        return np.array([ver_up, ver_down, hor_up, hor_down])\n        \n\n        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Чтение и форматирование данных"},{"metadata":{},"cell_type":"markdown","source":"## Таблица с целями"},{"metadata":{},"cell_type":"markdown","source":"Целевая таблица:"},{"metadata":{"trusted":true},"cell_type":"code","source":"target_frame_full = pd.read_csv('../input/digital-transformation-2020/Dataset/Dataset/OpenPart.csv')\n\ntarget_frame_full","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Следующий код преобразует таблицу таким образом, чтобы остался только столбец уникальных имён и столбец цели:"},{"metadata":{"trusted":true},"cell_type":"code","source":"def table_preparation(table):\n    image_names = table['Case'].values\n\n    def get_sample_name(sample_number):\n        return [f'{code[0]}_s{sample_number}.png' for code in (t.split('.') for t in image_names)]\n\n    samples_names = get_sample_name(1) + get_sample_name(2) + get_sample_name(3)\n    \n    target_frame = pd.DataFrame({\n        'names': samples_names,\n        'target': np.concatenate([table.iloc[:,1].values, table.iloc[:,2].values, table.iloc[:,3].values])\n    })\n\n    return target_frame\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_frame_full = table_preparation(target_frame_full)\n\ntarget_frame_full","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Чтение и трансформация выборки"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"fig_df = pd.read_csv('../input/digital-transformation-2020/Dataset/Dataset/DX_TEST_RESULT_FULL.csv').iloc[:,:-1].rename(columns=lambda x: x.strip()) # последний столбец пустой, имена содержат лишние пробелы\n\nfig_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Далее я добавляю к таблице столбец `name`, который является ключом для соединения с `target_frame`"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig_df['user_name'].drop_duplicates() # имена доступных сущностей","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig_samples = fig_df.query(\"user_name != 'Expert'\")\n\nnew_name = [f\"{file}_s{s[-1]}.png\" for file, s in zip (fig_samples['file_name'], fig_samples['user_name'])]\n\nfig_samples['name'] = new_name\n\nfig_samples","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Аналогичная таблица у эксперта (но здесь уточнять имя уже не нужно):"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig_expert = fig_df.query(\"user_name == 'Expert'\").drop('user_name', 1)\nfig_expert","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Перегон в словари"},{"metadata":{},"cell_type":"markdown","source":"Теперь каждому изображению (из масок моделей и эксперта) нужно поставить в соотвествие список входящих в него сущностей, ибо дальше работа ведётся именно с этими сущностями."},{"metadata":{"trusted":true},"cell_type":"code","source":"samples_dict = defaultdict(list)\n\nfor name, x, y, h, v, s in zip(fig_samples['name'], fig_samples['xcenter'], fig_samples['ycenter'], fig_samples['rhorizontal'], fig_samples['rvertical'], fig_samples['shape']):\n    p = Point(x,y)\n    samples_dict[name].append(Figure(p, h, v, s))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"expert_dict = defaultdict(list)\n\nfor name, x, y, h, v, s in zip(fig_expert['file_name'], fig_expert['xcenter'], fig_expert['ycenter'], fig_expert['rhorizontal'], fig_expert['rvertical'], fig_expert['shape']):\n    p = Point(x,y)\n    expert_dict[name].append(Figure(p, h, v, s))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Эта функция обрезает конец имени изображения модели, чтобы по нему можно было взять объекты эксперта"},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_end(string):\n    \"\"\"\n    преобразует 12345_000_s1.png в 12345_000\n    \"\"\"\n    t = string.split('_')\n    return f'{t[0]}_{t[1]}'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Удаление лишних наблюдений"},{"metadata":{},"cell_type":"markdown","source":"Под \"лишними\" подразумеваются пары снимков модель-образец, у которых либо нет объектов на обоих снимках (тогда это категория 5, потому что модель не нашла ничего на плохом снимке), либо нет объектов только на одном из снимков (тогда это категория 1, потому что модель либо вообще не нашла нужное, либо нашла что-то на идеальном снимке)."},{"metadata":{"trusted":true},"cell_type":"code","source":"bad_mask = [(len(samples_dict[name]) > 0) and (len(expert_dict[remove_end(name)]) > 0) for name in target_frame_full['names']]\n\ntarget_frame = target_frame_full.iloc[np.array(bad_mask),:]\n\ntarget_frame","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Реализация штрафов"},{"metadata":{},"cell_type":"markdown","source":"Для каждой пары конфигураций модель-эксперт нужно произвести разбор их объектов, сравнения и т. п. Каждая необходимая трансформация имеет свою категорию и свои диапазоны значений.\n\nВ итоге разбора **создается словарь с суммами по категориям штрафов** (эти суммы, не зависимые от конкретных значений штрафа, будем называть наказаниями). Это нужно сделать и сохранить заранее с той целью, чтобы избежать повторяющихся разборов, то есть лишних накладных расходов. Кроме того, конкретные значения штрафов заранее неизвестны, их нужно подбирать; и удобнее всего будет просто умножать штрафы на сохраненные значения. "},{"metadata":{},"cell_type":"markdown","source":"Получаемый в итоге словарь имеет следующие элементы:\n\n* `to_delete`: сумма площадей фигур, которые требуется удалить (удалить у модели, ибо у эксперта их нет, они лишние)\n* `to_create`: сумма площадей фигур, которые требуется добавить (ибо модель их не обнаружила)\n* `shape`: сумма особых площадей фигур, у которых нужно поменять форму (особая площадь -- это разность между площадью прямоугольника и площадью эллипса; здесь имеется в виду, что изменение формы должно чего-то стоить, но это не настолько страшно, как отсутствие нужной фигуры)\n* `shift`: сумма расстояний, на которые нужно сдвинуть некоторые фигуры модели, чтобы получить фигуры эксперта,\n* `ver_up`: сумма, связанная с наказанием за необходимость увеличивать вертикальную сторону (увеличивать у фигуры модели, чтобы совпало с фигурой эксперта); сами значения внутри суммы всегда равны большее/меньшее*(длину стороны у фигуры эксперта)\n* `ver_down`: то же самое, только за уменьшение по вертикали\n* `hor_up`: то же самое за увеличение по горизонтали\n* `hor_down`: за уменьшение по горизонтали\n\nКаждому из этих элементов будет соответствовать свой штраф."},{"metadata":{},"cell_type":"markdown","source":"Другие параметры алгоритма:\n\n* `tresh`: максимальное расстояния между центрами фигур (фигуры у модели и фигуры у эксперта), чтобы считать эти фигуры идентичными (одна как бы должна свестись к другой, потому что покрывают они один и тот же объект)\n* `coef`: итоговая сумма по штрафам выражается формулой\n\n$$ s = s_{global} + over \\cdot k_{over} + coef \\cdot avg(s_{local})$$\n\n\nгде $s_{global}$ -- штрафы за добавление/удаление фигур, $k_{over}$ -- количество несоотвествующих фигур, $avg(s_{local})$ -- сумма штрафов за перемещения/изменения размеров, деленное на число фигур, которые в этом участвовали. `coef` меняет значимость этого слагаемого\n* `over`: штраф за фигуры без соответствий\n"},{"metadata":{},"cell_type":"markdown","source":"Следующая функция кеширует набор чисел, на которые нужно умножать штрафы, для каждой пары конфигураций модель-эксперт:"},{"metadata":{"trusted":true},"cell_type":"code","source":"@lru_cache(maxsize = 10000)\ndef cache_pairs(name_sample, name_exp, tresh):\n    \n    sample_arr = samples_dict[name_sample]\n    expert_arr = expert_dict[name_exp]\n    \n    answer = defaultdict(float)\n    \n    ls = len(sample_arr)\n    le = len(expert_arr)\n    \n    # следующий закомментрированный код раньше использовался, но теперь момент отсутствия фигур на минимум одном из изображений мы рассматриваем особо \n    \n    #if ls == 0 and le == 0: # если модель и эксперт не находят патологий\n    #    return answer, 0, 0\n    \n    #if ls > 0 and le == 0: # если эксперт ничего не нашел, а модель нашла, нужно наказать модель пропорционально площади лишних объектов\n    #    answer['to_delete'] = sum((obj.S for obj in sample_arr))\n    #    return answer, 0, ls\n    \n    #if ls == 0 and le > 0: # если модель ничего не нашла, а эксперт нашел, нужно наказать модель пропорционально площади несозданных объектов\n    #    answer['to_create'] = sum((obj.S for obj in expert_arr))\n    #    return answer, 0, le\n    \n    \n    # матрица расстояний для пар объектов\n    dist = np.empty((ls, le), dtype = np.float32)\n    for x in range(ls):\n        for y in range(le):\n            dist[x, y] = Figure.dist(sample_arr[x], expert_arr[y])\n    \n    # дальше нужно определить все объекты с попарными расстоями не больше tresh\n    dist_ravel = dist.ravel()\n    \n    s, e = [], [] # годные фигуры у каждого\n    for i in np.argsort(dist_ravel): # начинаем искать пары по самым маленьким расстояниям в матрицу\n        if dist_ravel[i] >= tresh:\n            break\n        \n        si, se = (i) // le, (i+1) % le - 1 # перевод индексов из ravel в матричные\n        #print(f's = {s} si = {si} i = {i} ravel = {dist_ravel}')\n        s.append(sample_arr[si])\n        e.append(expert_arr[se])\n        \n        answer['shift'] += dist_ravel[i] # суммирование штрафов за сдвиг\n    \n    \n    # лишние объекты удаляются, недостающие объекты создаются \n    answer['to_delete'] = sum((obj.S for obj in sample_arr if obj not in s))\n    answer['to_create'] = sum((obj.S for obj in expert_arr if obj not in e))    \n    \n    \n    transforms = np.zeros(4)\n    for model_result, expert_result in zip(s, e):\n        transforms += Figure.transforms(model_result, expert_result) # по каждый паре идентичных объектов суммируем наказания\n        \n        if model_result.shape != expert_result.shape: # если надо поменять форму, за это тоже наказание\n            answer['shape'] += expert_result.S_diff()\n    \n    \n    answer['ver_up'] = transforms[0]\n    answer['ver_down'] = transforms[1]\n    answer['hor_up'] = transforms[2]\n    answer['hor_down'] = transforms[3]\n    \n    return answer, len(s), math.fabs(ls - le) # последние два слагаемых удобнее выводить отдельно, не используя словарь","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Эта функция возвращает результат для пары \"снимков\" и дополнительных параметров алгоритма (суммирует штрафы по полученным словарям):"},{"metadata":{"trusted":true},"cell_type":"code","source":"glob_set = set(['to_delete', 'to_create']) # категории, за которые штраф не усредняется\n\ndef result_function(sample_arr, expert_arr, name_sample, name_exp, tresh, params, coef = 5, over = 10): # name_sample, name_exp приходится использовать для хеширования, не хватило времени переписать код более чисто\n    \n    punishes, count, bad_count = cache_pairs(name_sample, name_exp, tresh)\n    \n    glob_sum = sum((params[key]*punishes[key] for key in glob_set)) # сумма по неусредняемым наказаниям\n    \n    if count > 0:\n        sm = sum((params[key]*punishes[key] for key in params.keys() if key not in glob_set)) # сумма по усредняемым наказаниям\n        return glob_sum + bad_count*over + sm/count*coef\n    else:\n        return glob_sum + bad_count*over","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Пример использования при случайных параметрах"},{"metadata":{},"cell_type":"markdown","source":"## Создаем результирующую функцию с некоторыми фиксированными параметрами алгоритма "},{"metadata":{},"cell_type":"markdown","source":"Как видно, какие-то параметры мы храним в словаре, а какие-то легче передавать отдельно."},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\n    'to_delete': 2,\n    'to_create': 10,\n    'shape': 1,\n    'shift': 8,\n    'ver_up': 2,\n    'ver_down': 2,\n    'hor_up': 2,\n    'hor_down': 2\n}\n\ndef some_function(sample_arr, expert_arr, name_sample, name_exp):\n    return result_function(sample_arr, expert_arr, name_sample, name_exp, tresh = 30, params = params, coef = 5, over = 1000)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Результаты предсказания"},{"metadata":{"trusted":true},"cell_type":"code","source":"answer = [some_function(samples_dict[sample_arr], expert_dict[remove_end(sample_arr)], sample_arr, remove_end(sample_arr)) for sample_arr in target_frame['names']]\n\nres = target_frame.copy()\nres['predicted'] = answer\n\nres","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Пока что цель лишь в том, чтобы делать предсказания с сохранением порядка (то есть самые маленькие значения должны уходить в группу 5, самые большие, у которых максимальные штрафы, в 1). Следующая функция реализует простую метрику оценки качества предыдущего результата"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_corr(frame):\n    \"\"\"\n    корреляция Спирмена\n    \n    поскольку цель инвертирована, эту корреляцию нужно минимизировать, устремляя к -1\n    \"\"\"\n    \n    return stats.spearmanr(frame['target'].values, frame['predicted'].values).correlation # корреляция Спирмена, чтобы сохранять порядок\n\nget_corr(res)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Посмотрим несколько примеров масок с оценкой эксперта и нашим штрафом:"},{"metadata":{"trusted":true},"cell_type":"code","source":"for ind in (0, 1, 2, 3, 4, 5, 6, 7):\n    \n    sample_arr = target_frame_full['names'][ind]\n    answer = some_function(samples_dict[sample_arr], expert_dict[remove_end(sample_arr)], sample_arr, remove_end(sample_arr))\n\n    expert = Image.open(f'../input/digital-transformation-2020/Dataset/Dataset/Expert/{remove_end(sample_arr)}_expert.png')\n\n    model = Image.open(f'../input/digital-transformation-2020/Dataset/Dataset/sample_1/{sample_arr}')\n\n    fig, axes = plt.subplots(1, 2)\n\n    axes[0].imshow(np.asarray(model))\n    axes[0].set_title(f'Маска модели, штраф {answer}')\n\n    axes[1].imshow(np.asarray(expert))\n    axes[1].set_title(f\"Маска эксперта, оценка {target_frame_full.query('names == @sample_arr')['target'].values[0]}\")\n\n    fig.set_figwidth(18)    #  ширина и\n    fig.set_figheight(10)    #  высота \"Figure\"\n\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Из первого графика можно сделать вывод, что обнаружение объектов на идеальном снимке или их необнаружение на снимке с патологией сразу означает 1."},{"metadata":{},"cell_type":"markdown","source":"# Эволюционный алгоритм"},{"metadata":{},"cell_type":"markdown","source":"Оптимальные параметры будем искать **методом роя частиц** (реализованным мной и хранящимся https://github.com/PasaOpasen/BeehiveMethod).\n\nСперва мы пользовались простым генетическим алгоритмом (источник: https://github.com/rmsolgi/geneticalgorithm), но оказалось, что метод роя частиц дает такие же результаты, но сходится в несколько раз быстрее. На всякий случай прежний метод поиска генетическим алгоритмом сохранён, его можно опробовать."},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate(df, params):\n    \"\"\"\n    функция, которая датафрейму и параметрам алгоритма сопоставляет ошибку на этом датафрейме\n    \"\"\"\n    \n    # некоторые параметры храним в словаре, некоторые используем отдельно\n    pr = {\n        'to_delete': params[2],\n        'to_create': params[3],\n        'shape': params[4],\n        'shift': params[5],\n        'ver_up': params[6],\n        'ver_down': params[7],\n        'hor_up': params[8],\n        'hor_down': params[9]\n    }\n    \n    def some_function(sample_arr, expert_arr, name_sample, name_exp):\n        return result_function(sample_arr, expert_arr, name_sample, name_exp, tresh = params[0], params = pr, coef = params[1], over = params[10])\n    \n    answer = [some_function(samples_dict[sample_arr], expert_dict[remove_end(sample_arr)], sample_arr, remove_end(sample_arr)) for sample_arr in df['names']]\n\n    res = df.copy()\n    res['predicted'] = answer\n\n    return get_corr(res)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def find_solution_ga(df):\n    \"\"\"\n    поиск оптимальных параметров генетическим алгоритмом\n    \"\"\"\n    \n    def f(X):\n        return evaluate(df, X)\n    \n    # границы по каждому параметру\n    varbound = np.array([\n        [0, 500], # tresh\n        [0, 20], # coef\n        [0, 2000], # to_delete\n        [0, 1000], # to_create\n        [0, 20], # shape\n        [0, 1000], # shift\n        [0, 50], # ver_up\n        [0, 300], # ver_down\n        [0, 50], # hor_up\n        [0, 150], # hor_down\n        [0, 10000] #over\n    ])\n    \n    param = {\n        'max_num_iteration': 400, \n        'population_size': 500, \n        'mutation_probability': 0.15, \n        'elit_ratio': 0.05, \n        'crossover_probability': 0.5, \n        'parents_portion': 0.3, \n        'crossover_type': 'two_point', \n        'max_iteration_without_improv': 50\n    }\n\n\n    model = ga(function = f, dimension = 11, variable_type = 'real', variable_boundaries = varbound, algorithm_parameters = param)\n\n    model.run()\n    \n    \n    return model.output_dict['variable']\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def find_solution(df):\n    \"\"\"\n    поиск оптимальных параметров методом роя частиц\n    \"\"\"\n    \n    def f(X):\n        return evaluate(df, X)\n    \n    # границы по каждому параметру\n    varbound = np.array([\n        [0, 500], # tresh\n        [0, 20], # coef\n        [0, 2000], # to_delete\n        [0, 1000], # to_create\n        [0, 20], # shape\n        [0, 1000], # shift\n        [0, 50], # ver_up\n        [0, 300], # ver_down\n        [0, 50], # hor_up\n        [0, 150], # hor_down\n        [0, 10000] #over\n    ])\n    \n    count = 300\n    \n    # массив случайных чисел, но каждый столбец должен быть из своего диапазона\n    arr = np.zeros((count, len(varbound)))\n    \n    for i, bound in enumerate(varbound):\n        arr[:, i] = np.random.uniform(low = bound[0], high = bound[1], size = count)\n    \n    \n    bees = Bees(arr, width = 0.2)\n    \n    hive = Hive(bees, \n            f, \n            parallel = False, # use parallel evaluating of functions values for each bee? (recommented for heavy functions, f. e. integtals) \n            verbose = True) # show info about hive \n    \n    best_result, best_position = hive.get_result(max_step_count = 100, # maximun count of iteraions\n                      max_fall_count = 30, # maximum count of continious iterations without better result\n                      w = 0.3, fp = 2, fg = 5, # parameters of algorithm\n                      latency = 1e-9, # if new_result/old_result > 1-latency then it was the iteration without better result\n                      verbose = True # show the progress\n                      )\n    \n    return best_position\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate_global(solution_seeker = find_solution, cv = 5, repeats = 5):\n    \"\"\"\n    это функция для повторной кросс-валидации, но мы ее не использовали, потому что не было на это времени\n    \"\"\"\n    \n    total = []\n    \n    for _ in range(repeats):\n    \n        inds = np.random.randint(cv, size = target_frame.shape[0])\n\n        for i in range(cv):\n            mask = inds != i\n            solution = solution_seeker(target_frame.iloc[mask,:])\n            total.append(evaluate(target_frame.iloc[np.logical_not(mask),:], solution))\n\n    return solution, np.mean(total)\n\n\n# получить лучшие параметры в виде одномерного массива\nbest_params = find_solution(target_frame)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Визуализация решения"},{"metadata":{},"cell_type":"markdown","source":"По найденным параметрам строим решение (пока что в метриках штрафов):"},{"metadata":{"trusted":true},"cell_type":"code","source":"params = best_params\n\npr = {\n        'to_delete': params[2],\n        'to_create': params[3],\n        'shape': params[4],\n        'shift': params[5],\n        'ver_up': params[6],\n        'ver_down': params[7],\n        'hor_up': params[8],\n        'hor_down': params[9]\n}\n    \ndef some_function(sample_arr, expert_arr, name_sample, name_exp):\n    return result_function(sample_arr, expert_arr, name_sample, name_exp, tresh = params[0], params = pr, coef = params[1], over = params[10])\n\n\n\nanswer = [some_function(samples_dict[sample_arr], expert_dict[remove_end(sample_arr)], sample_arr, remove_end(sample_arr)) for sample_arr in target_frame['names']]\n\nres = target_frame.copy()\nres['predicted'] = answer\n\nres","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Нарисуем полученные величины так, чтоб было видно, насколько удалось сохранить порядок:"},{"metadata":{"trusted":true},"cell_type":"code","source":"res = res.sort_values(['predicted'])\n\nscatter = plt.scatter(np.arange(res.shape[0]), res['predicted'], c = res['target'].values)\n\nplt.legend(handles = scatter.legend_elements()[0], labels = set(list(res['target'].values)))\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Теперь нужно свести исходные диапазоны к требуемым (от 1 до 5). Создадим линейную модель, где исходный диапазон будет предиктором. Сейчас корреляция между целью и предиктором равна:"},{"metadata":{"trusted":true},"cell_type":"code","source":"stats.pearsonr(res['predicted'], res['target'])[0] ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Если сделать преобразование Бокса-Кокса, она вырастет почти в два раза:"},{"metadata":{"trusted":true},"cell_type":"code","source":"bx, lambd = stats.boxcox(res['predicted'])\nprint(stats.pearsonr(bx, res['target'])[0] )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def tobx(vector):\n    \"\"\"\n    делает то же самое преобразование, используя сохраненный параметр\n    \"\"\"\n    if lambd == 0:\n        return np.log(vector)\n    return (vector**lambd - 1)/lambd","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Визуализация после преобразования: "},{"metadata":{"trusted":true},"cell_type":"code","source":"scatter = plt.scatter(np.arange(res.shape[0]), bx, c = res['target'].values)\n\nplt.legend(handles = scatter.legend_elements()[0], labels = set(list(res['target'].values)))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Построим простейшую линейную модель по этим данным:"},{"metadata":{"trusted":true},"cell_type":"code","source":"slope, intercept, r_value, p_value, std_err = stats.linregress(bx, res['target'])\n\nslope, intercept, r_value, p_value, std_err   ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Зафиксируем полученные преобразования в рамках одной функции:"},{"metadata":{"trusted":true},"cell_type":"code","source":"def convert2onefive(vector):\n    answer = vector.copy()\n    \n    zero = vector == 0\n    not_zero = np.logical_not(zero)\n    \n    vector2 = vector[not_zero]\n    answer[not_zero] = tobx(vector[not_zero])*slope + intercept\n    answer[zero] = 5 # 0 штраф -- считаем за лучший счет, значит класс 5 (исключения потом наложатся поверх, так что не страшно пока оставить этот код)\n    \n    answer[answer<1] = 1\n    answer[answer>5] = 5\n    \n    return answer\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Выполним предсказание на исходных данных:"},{"metadata":{"trusted":true},"cell_type":"code","source":"results = pd.DataFrame({\n    'predicted': convert2onefive(res['predicted'].values),\n    'goal': res['target']\n})\n\nprint(f\"MAE = {np.mean(np.abs(results['predicted'] - results['goal']))}\")\n\nresults","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Осталось сделать то же самое для тестовых данных."},{"metadata":{},"cell_type":"markdown","source":"# Предсказание"},{"metadata":{},"cell_type":"markdown","source":"Прочтем образец:"},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = pd.read_csv('../input/digital-transformation-2020/SecretPart_dummy.csv')\n\npreds","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Как и раньше, сведём его к таблице с двумя столбцами:"},{"metadata":{"trusted":true},"cell_type":"code","source":"preds2 = table_preparation(preds)\n\npreds2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Собственно, сделаем само предсказание:"},{"metadata":{"trusted":true},"cell_type":"code","source":"answer = [some_function(samples_dict[sample_arr], expert_dict[remove_end(sample_arr)], sample_arr, remove_end(sample_arr)) for sample_arr in preds2['names']]\n\npreds2['target'] = convert2onefive(np.array(answer))\n\n# работа с \"лишними\" парами\npreds2['target'][np.array([(len(samples_dict[sample_arr]) == 0) and (len(expert_dict[remove_end(sample_arr)]) == 0) for sample_arr in preds2['names']])] = 5 # если нет объектов в обоих снимках, это 5\n\npreds2['target'][np.logical_not(np.array([(len(samples_dict[sample_arr]) > 0) and (len(expert_dict[remove_end(sample_arr)]) > 0) for sample_arr in preds2['names']]))] = 1 # если нет объектов только на одном из снимков, это 1\n                          \npreds2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Вставим полученные значения в исходную таблицу:"},{"metadata":{"trusted":true},"cell_type":"code","source":"for col, arr in zip(preds.columns[1:], np.array_split(preds2['target'].values, 3)):\n    preds[col] = arr\n\npreds","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Сохраним решение:"},{"metadata":{"trusted":true},"cell_type":"code","source":"preds.to_csv('AK_output.csv', index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}